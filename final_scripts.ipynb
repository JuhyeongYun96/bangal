{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "70c1de47-4e48-428e-b4c2-95cc6e864320",
    "_kg_hide-output": true,
    "_uuid": "ca2c7280-2415-4dff-94cf-4e0ad517cc81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/mlfw/tensorflow_gpu/Python-3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general packages\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sklearns \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split \n",
    "import random\n",
    "import cv2\n",
    "import gc\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.optimizers import Adam, Nadam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D, GlobalMaxPooling2D\n",
    "from keras.layers import (MaxPooling2D, Input, Average, Activation, MaxPool2D,\n",
    "                          Flatten, LeakyReLU, BatchNormalization, concatenate)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger)\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "from keras.utils import Sequence\n",
    "from keras import utils as np_utils\n",
    "from keras.callbacks import (Callback, ModelCheckpoint,\n",
    "                                        LearningRateScheduler,EarlyStopping, \n",
    "                                        ReduceLROnPlateau,CSVLogger)\n",
    "\n",
    "import albumentations\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose,DualTransform, IAAAffine,IAAPerspective\n",
    ")\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import efficientnet.keras as efn \n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "02ff580a-dd3e-4922-b919-7712064efe6a",
    "_uuid": "95622995-f68a-467a-9195-fe878a052176"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "      <td>../137x236/Train_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "      <td>../137x236/Train_1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "      <td>../137x236/Train_2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "      <td>../137x236/Train_3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "      <td>../137x236/Train_4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme  \\\n",
       "0  Train_0             15                9                    5   ক্ট্রো   \n",
       "1  Train_1            159                0                    0        হ   \n",
       "2  Train_2             22                3                    5     খ্রী   \n",
       "3  Train_3             53                2                    2     র্টি   \n",
       "4  Train_4             71                9                    5     থ্রো   \n",
       "\n",
       "                 filename  \n",
       "0  ../137x236/Train_0.png  \n",
       "1  ../137x236/Train_1.png  \n",
       "2  ../137x236/Train_2.png  \n",
       "3  ../137x236/Train_3.png  \n",
       "4  ../137x236/Train_4.png  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 2020\n",
    "batch_size = 64*8\n",
    "FACTOR = 1.0\n",
    "stats = (0.0692, 0.2051)\n",
    "\n",
    "HEIGHT = 137 \n",
    "WIDTH = 236\n",
    "gpus = 4\n",
    "dim = (int(HEIGHT * FACTOR), int(WIDTH * FACTOR))\n",
    "resize_wid = int(WIDTH * FACTOR)\n",
    "resize_hit = int(HEIGHT * FACTOR)\n",
    "\n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_all(SEED)\n",
    "\n",
    "# load files\n",
    "im_path = '../137x236/'\n",
    "train = pd.read_csv('../input/bengaliai-cv19/train.csv')\n",
    "test = pd.read_csv('../input/bengaliai-cv19/test.csv')\n",
    "train['filename'] = train.image_id.apply(lambda filename: im_path + filename + '.png')\n",
    "\n",
    "# top 5 samples\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Stratification\n",
    "\n",
    "From [Abhishek Thakur](https://www.youtube.com/watch?v=8J5Q4mEzRtY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b511512a-1754-4229-8bf7-cea43d1af56a",
    "_uuid": "a348aefb-6348-4e4f-9d7a-33ef18ba8dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    40168\n",
      "3    40168\n",
      "2    40168\n",
      "1    40168\n",
      "0    40168\n",
      "Name: fold, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train.loc[:, 'fold'] = -1\n",
    "X = train.image_id.values\n",
    "y = train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, random_state=1)\n",
    "for fold, (tr, vl) in enumerate(mskf.split(X,y)):\n",
    "    train.loc[vl, 'fold'] = fold\n",
    "    \n",
    "print(train.fold.value_counts())\n",
    "train.to_csv('fold_trian', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "d8be143f-74ab-480a-adfd-28102765fda2",
    "_uuid": "2230f108-f8d3-43db-80db-08f4b76c89eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_145648</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>নৃ</td>\n",
       "      <td>../137x236/Train_145648.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_24895</td>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>ল্কে</td>\n",
       "      <td>../137x236/Train_24895.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_75994</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>ণে</td>\n",
       "      <td>../137x236/Train_75994.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_442</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>জ্য</td>\n",
       "      <td>../137x236/Train_442.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_177898</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>র্কো</td>\n",
       "      <td>../137x236/Train_177898.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme  \\\n",
       "0  Train_145648             81                6                    0       নৃ   \n",
       "1   Train_24895            125                7                    0     ল্কে   \n",
       "2   Train_75994             59                7                    0       ণে   \n",
       "3     Train_442             43                0                    4      জ্য   \n",
       "4  Train_177898             13                9                    2     র্কো   \n",
       "\n",
       "                      filename  fold  \n",
       "0  ../137x236/Train_145648.png     3  \n",
       "1   ../137x236/Train_24895.png     0  \n",
       "2   ../137x236/Train_75994.png     4  \n",
       "3     ../137x236/Train_442.png     1  \n",
       "4  ../137x236/Train_177898.png     3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_train = pd.read_csv('fold_trian')\n",
    "fold_train = fold_train.sample(frac=1).reset_index(drop=True) # shufling\n",
    "fold_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.augmentations import functional as Func\n",
    "\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "    \n",
    "    Author: Qishen Ha\n",
    "    Email: haqishen@gmail.com\n",
    "    2020/01/29\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = Func.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "228de286-0b27-4a58-93fd-21d8fb328cf2",
    "_uuid": "689422ec-2647-4a07-969f-34448b092ff9"
   },
   "source": [
    "# Grapheme Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "3d804dad-1284-4bab-93ed-168ce39ada9d",
    "_uuid": "bde05fdb-3185-4da4-af2f-fe8aa21fa185"
   },
   "outputs": [],
   "source": [
    "class GraphemeGenerator(Sequence):\n",
    "    def __init__(self, data, batch_size, dim, kfold = (1,), shuffle=False, transform = None):\n",
    "        \n",
    "        data = data[[\"image_id\", \"grapheme_root\", \"vowel_diacritic\",\n",
    "                     \"consonant_diacritic\", \"fold\"]]\n",
    "        data = data[data.fold.isin(kfold)].reset_index(drop=True)\n",
    "        self._data = data\n",
    "        \n",
    "        self._label_1 = pd.get_dummies(self._data['grapheme_root'], \n",
    "                                       columns = ['grapheme_root'])\n",
    "        self._label_2 = pd.get_dummies(self._data['vowel_diacritic'], \n",
    "                                       columns = ['vowel_diacritic'])\n",
    "        self._label_3 = pd.get_dummies(self._data['consonant_diacritic'], \n",
    "                                       columns = ['consonant_diacritic'])\n",
    "        self._list_idx = data.index.values\n",
    "        self._batch_size = batch_size\n",
    "        self._dim = dim\n",
    "        self._shuffle = shuffle\n",
    "        self._transform = transform\n",
    "        self._kfold = kfold\n",
    "        self.on_epoch_end()  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self._data)/self._batch_size))\n",
    "    \n",
    "    \n",
    "    def get_all_valid_y(self):\n",
    "        total = self.__len__()* self._batch_size\n",
    "        Target_1 = np.empty((total, 168), dtype = float)\n",
    "        Target_2 = np.empty((total,  11), dtype = float)\n",
    "        Target_3 = np.empty((total,   7), dtype = float)        \n",
    "        for i, k in enumerate(self._indices):\n",
    "            if total == i :\n",
    "                break\n",
    "            Target_1[i,:] = self._label_1.loc[k, :].values\n",
    "            Target_2[i,:] = self._label_2.loc[k, :].values\n",
    "            Target_3[i,:] = self._label_3.loc[k, :].values\n",
    "        return [Target_1, Target_2, Target_3]    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self._indices[index*self._batch_size:(index+1)*self._batch_size]\n",
    "        _idx = [self._list_idx[k] for k in batch_idx]\n",
    "\n",
    "        Data     = np.empty((self._batch_size, *self._dim, 1))\n",
    "\n",
    "        Target_1 = np.empty((self._batch_size, 168), dtype = float)\n",
    "        Target_2 = np.empty((self._batch_size,  11), dtype = float)\n",
    "        Target_3 = np.empty((self._batch_size,   7), dtype = float)\n",
    "        \n",
    "        for i, k in enumerate(_idx):\n",
    "            image = cv2.imread(im_path + self._data['image_id'][k] + '.png') \n",
    "            image = cv2.resize(image, (resize_wid, resize_hit)) \n",
    "            if len(self._kfold) != 1: # train\n",
    "                if self._transform is not None:\n",
    "                    image =  self._transform(image=image)['image']\n",
    "                    \n",
    "            gray = lambda rgb : np.dot(rgb[... , :3] , [0.299 , 0.587, 0.114]) \n",
    "            image = gray(image) \n",
    "            \n",
    "            image = (image.astype(np.float32)/255.0 - stats[0])/stats[1]\n",
    "            image = image[:, :, np.newaxis]\n",
    "            Data[i,:, :, :] =  image\n",
    "        \n",
    "            Target_1[i,:] = self._label_1.loc[k, :].values\n",
    "            Target_2[i,:] = self._label_2.loc[k, :].values\n",
    "            Target_3[i,:] = self._label_3.loc[k, :].values\n",
    "            \n",
    "        return Data, [Target_1, Target_2, Target_3]\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self._indices = np.arange(len(self._list_idx))\n",
    "        if self._shuffle:\n",
    "            np.random.shuffle(self._indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutMixGenerator(Sequence):\n",
    "    def __init__(self, generator1, generator2, cut_p = 0.2, maxcut= 0.5, mixup_p = 0.2, maxmix = 0.5):\n",
    "        self.generator1 = generator1\n",
    "        self.generator2 = generator2\n",
    "        self.cut_p = cut_p\n",
    "        self.mixup_p = mixup_p\n",
    "        self.batch_size = self.generator1._batch_size\n",
    "        self.maxcut = maxcut\n",
    "        self.maxmix = maxmix\n",
    "        self.on_epoch_end()  \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.generator1.__len__()\n",
    "        \n",
    "    def get_rand_bbox(self,width, height, l):\n",
    "        wcut = np.random.random()*l\n",
    "        hcut = np.random.random()*l\n",
    "        r_w = np.int(width * wcut)\n",
    "        r_h = np.int(height * hcut)\n",
    "        x = np.random.randint(width - r_w)\n",
    "        y = np.random.randint(height - r_h)\n",
    "        return x, y, r_w, r_h\n",
    "    \n",
    "    def smooth_labels(self,labels, factor=0.1):\n",
    "        labels *= (1 - factor)\n",
    "        labels += (factor / labels.shape[0])\n",
    "        return labels\n",
    "\n",
    "    def cutmix(self,X1, X2, y1, y2):\n",
    "        width = X1.shape[1]\n",
    "        height = X1.shape[0]\n",
    "        x, y, r_w, r_h = self.get_rand_bbox(width, height, self.maxcut)\n",
    "        X1[ y:y+r_h, x:x+r_w, :] = X2[ y:y+r_h, x:x+r_w, :]\n",
    "        ra = (r_w*r_h) / (width*height)\n",
    "        y= []\n",
    "        for i in range(len(y1)):\n",
    "            ysm1 = self.smooth_labels(y1[i])\n",
    "            ysm2 = self.smooth_labels(y2[i])\n",
    "            y.append((ysm1*(1.0-ra)) + (ysm2*ra))\n",
    "        return X1, y\n",
    "    \n",
    "    def mixup(self, X1, X2, y1, y2):\n",
    "        X = np.zeros(X1.shape)\n",
    "        ra = np.random.random()*self.maxmix\n",
    "        X = X1*(1-ra) + X2*ra\n",
    "        y= []\n",
    "        for i in range(len(y1)):\n",
    "            ysm1 = self.smooth_labels(y1[i])\n",
    "            ysm2 = self.smooth_labels(y2[i])\n",
    "            y.append((ysm1*(1.0-ra)) + (ysm2*ra))\n",
    "        return X,y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        Data, [Target_1, Target_2, Target_3] = self.generator1.__getitem__(index)\n",
    "        cutmix_idx = np.random.choice(np.arange(self.batch_size),int(self.batch_size*self.cut_p), replace=False)\n",
    "        \n",
    "        for idx in cutmix_idx:\n",
    "            srcidx = np.random.randint(self.generator2.__len__())\n",
    "            orgD, orgT_1, orgT_2, orgT_3 = Data[idx,:], Target_1[idx,:], Target_2[idx,:], Target_3[idx,:]\n",
    "            srcD, [srcT_1, srcT_2, srcT_3] = self.generator2.__getitem__(srcidx)\n",
    "            mD, [mT1,mT2,mT3] = self.cutmix(orgD,srcD[0], [orgT_1, orgT_2, orgT_3], [srcT_1[0], srcT_2[0], srcT_3[0]])\n",
    "            Data[idx,:], [Target_1[idx,:], Target_2[idx,:], Target_3[idx,:]] = mD, [mT1,mT2,mT3]\n",
    "            \n",
    "            \n",
    "        mixup_idx = np.random.choice(np.arange(self.batch_size),int(self.batch_size*self.mixup_p), replace=False)\n",
    "        \n",
    "        for idx in mixup_idx:\n",
    "            srcidx = np.random.randint(self.generator2.__len__())\n",
    "            orgD, orgT_1, orgT_2, orgT_3 = Data[idx,:], Target_1[idx,:], Target_2[idx,:], Target_3[idx,:]\n",
    "            srcD, [srcT_1, srcT_2, srcT_3] = self.generator2.__getitem__(srcidx)\n",
    "            mD, [mT1,mT2,mT3] = self.mixup(orgD,srcD[0], [orgT_1, orgT_2, orgT_3], [srcT_1[0], srcT_2[0], srcT_3[0]])\n",
    "            Data[idx,:], [Target_1[idx,:], Target_2[idx,:], Target_3[idx,:]] = mD, [mT1,mT2,mT3]        \n",
    "        \n",
    "        return Data, [Target_1, Target_2, Target_3]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.generator1.on_epoch_end()\n",
    "        self.generator2.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c323487b-7bdc-4fd0-bf03-da1719840c7d",
    "_uuid": "8399bd1a-478e-4f70-ab3e-63ce66504e5e"
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "For the augmentation part, I'm simply following [XingJian Lyu](https://www.kaggle.com/roguekk007)'s suggestion that he'd mentioned in [Useful Baseline Data Augmentations?](https://www.kaggle.com/c/bengaliai-cv19/discussion/132642), specificly in [here](https://www.kaggle.com/c/bengaliai-cv19/discussion/132642#759415). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "            ], p=0.1),\n",
    "    \n",
    "            OneOf([\n",
    "                MotionBlur(p=0.2),\n",
    "                MedianBlur(blur_limit=3, p=0.1),\n",
    "                Blur(blur_limit=3, p=0.1),\n",
    "            ], p=0.1),\n",
    "    \n",
    "            OneOf([\n",
    "                OpticalDistortion(p=0.3),\n",
    "                GridDistortion(p=0.1),\n",
    "                IAAPiecewiseAffine(p=0.3),\n",
    "            ], p=0.1),\n",
    "            OneOf([\n",
    "                CLAHE(clip_limit=2),\n",
    "                IAASharpen(),\n",
    "                IAAEmboss(),\n",
    "                RandomBrightnessContrast(),\n",
    "            ], p=0.1),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "e26a82b5-0419-4b06-89cb-7bf503a40078",
    "_uuid": "11636c98-a4ce-41f7-9a58-75a818ec2f81"
   },
   "outputs": [],
   "source": [
    "train_transform = albumentations.Compose([\n",
    "                albumentations.OneOf([\n",
    "                    ShiftScaleRotate(scale_limit=.15, rotate_limit=10, \n",
    "                                     border_mode=cv2.BORDER_CONSTANT),\n",
    "                ],p = 0.2),\n",
    "    \n",
    "            OneOf([\n",
    "            MotionBlur(p=0.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "            ], p=0.1),\n",
    "\n",
    "                albumentations.OneOf([   \n",
    "                    GridMask(num_grid=(12,20), rotate=(-15,15), mode=0),\n",
    "                    GridMask(num_grid=(8,20), rotate=(-15,15), mode=1),\n",
    "                    GridMask(num_grid=(8,20), rotate=(-15,15), mode=2),\n",
    "            ],p = 0.2)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6e517d03-ad1e-4136-9b89-6eeab3f056c0",
    "_uuid": "a40f3402-dcf2-4820-8df7-65bc6c8f0073"
   },
   "source": [
    "## Visualize the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09e6cdc0-dbb3-4673-828f-c68b838fd91e",
    "_uuid": "93f3b58d-2e58-4615-88d2-1642332c1c9a"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weights_diff_input_ch(src, tar):\n",
    "    src_first = src.layers[1].get_weights()\n",
    "    src_first_sum = np.sum(src_first[0],axis=2)\n",
    "    tar_ch_num = tar.layers[1].get_weights()[0].shape[2]\n",
    "    src_first_sum /= tar_ch_num\n",
    "    tar_weight_list = []\n",
    "    for i in range(tar_ch_num):\n",
    "        tar_weight_list.append(src_first_sum)\n",
    "    tar_first_weight = np.stack(tar_weight_list,axis=2)\n",
    "    tar.layers[1].set_weights([tar_first_weight])\n",
    "    \n",
    "    for i in range(len(src.layers)):\n",
    "        if i < 2:\n",
    "            continue\n",
    "        tar.layers[i].set_weights(src.layers[i].get_weights())\n",
    "        \n",
    "    return tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, input_shape, slr = 0.003, gpus=1):\n",
    "    init_model = backbone(input_shape=input_shape, include_top=False, weights=None)\n",
    "    imagenet_model = backbone(weights='noisy-student', include_top=False)\n",
    "    base_model = copy_weights_diff_input_ch(imagenet_model,init_model)\n",
    "    curr_output = GlobalAveragePooling2D()(base_model.output)\n",
    "    oputput1 = Dense(168,  activation='softmax', name='gra') (curr_output)\n",
    "    oputput2 = Dense(11,  activation='softmax', name='vow') (curr_output)\n",
    "    oputput3 = Dense(7,  activation='softmax', name='cons') (curr_output)\n",
    "    output_tensor = [oputput1, oputput2, oputput3]\n",
    "\n",
    "    model = Model(base_model.input, output_tensor)\n",
    "    if gpus !=1:\n",
    "        model = multi_gpu_model(model,gpus=gpus, cpu_merge=False)\n",
    "    # compiling    \n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=slr), \n",
    "        loss = {'gra' : 'categorical_crossentropy', \n",
    "                'vow' : 'categorical_crossentropy', \n",
    "                'cons': 'categorical_crossentropy'},\n",
    "\n",
    "        loss_weights = {'gra' : 0.6,\n",
    "                        'vow' : 0.2,\n",
    "                        'cons': 0.2},\n",
    "        metrics={'gra' : 'accuracy', \n",
    "                 'vow' : 'accuracy', \n",
    "                 'cons': 'accuracy'}\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c35b3c9d-d693-4197-add5-b4ba0391c4e1",
    "_uuid": "0a4d6503-b785-4395-859e-0ed0638344da"
   },
   "source": [
    "## Competition Eval Metrics\n",
    "\n",
    "The following code cell is bit modified version of the original author and unfortunately I forget to where I found it; so can't give the credit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "bea4a366-fb7b-42f6-8e49-909ddddcf2fa",
    "_uuid": "bcfb2e23-e6e9-47fa-9a54-763fd15ce784"
   },
   "outputs": [],
   "source": [
    "def macro_recall(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, val_data, name):\n",
    "        super().__init__()\n",
    "        self.valid_data = val_data\n",
    "        self.batch_size = self.valid_data._batch_size\n",
    "        self.name = name\n",
    "        self.avg_recall = []\n",
    "        self.val_trues = {0: [], 1:[], 2:[]}\n",
    "        batches = len(self.valid_data)\n",
    "        yVal = self.valid_data.get_all_valid_y()\n",
    "        for i in range(3):\n",
    "            true = np.argmax(yVal[i], axis=1)\n",
    "            self.val_trues[i].extend(list(true))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.val_preds = {0: [], 1:[], 2:[]} \n",
    "        #self.val_trues = {0: [], 1:[], 2:[]}\n",
    "        \n",
    "        val_preds = model.predict_generator(val_generator,workers=8)\n",
    "        for i in range(3):\n",
    "            preds = np.argmax(val_preds[i], axis=1)    \n",
    "            self.val_preds[i].extend(list(preds))\n",
    "\n",
    "        recalls  = []\n",
    "        for i in range(3):\n",
    "            recalls.append(macro_recall(self.val_trues[i], self.val_preds[i]))\n",
    "            \n",
    "        avg_result = np.average(recalls, weights=[2, 1, 1])\n",
    "        self.avg_recall.append(avg_result)    \n",
    "\n",
    "        if avg_result == max(self.avg_recall):\n",
    "            print(len(self.val_trues[i]),\" sets validation Avg. Recall Improved. Saving model.\")\n",
    "            print(f\"Avg. Recall: {round(avg_result, 4)}\")\n",
    "            self.model.save_weights('best_avg_recall' + self.name +'.h5')\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "6bd239df-3077-4411-adca-76d87880782e",
    "_uuid": "086395c3-5b82-4671-b50d-18ea1b653792"
   },
   "outputs": [],
   "source": [
    "def Call_Back(name, val_generator):\n",
    "    # model check point\n",
    "    checkpoint = ModelCheckpoint(name+'.h5', \n",
    "                                 monitor = 'val_loss', \n",
    "                                 verbose = 0, save_best_only=True, \n",
    "                                 mode = 'min',\n",
    "                                 save_weights_only = True)\n",
    "    csv_logger = CSVLogger(name+'.csv')\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                   factor=0.3, patience=4,\n",
    "                                   verbose=1, mode='auto',\n",
    "                                   min_delta=0.0001, cooldown=1, min_lr=0.000001)\n",
    "    custom_callback = CustomCallback(val_generator, name)\n",
    "    return [checkpoint, csv_logger, reduceLROnPlat, custom_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "historys = []\n",
    "backbone = efn.EfficientNetB0\n",
    "disc = '_mul_addaug_EF0_Fold_'\n",
    "for i in range(5):\n",
    "    t_fold = np.setdiff1d(np.arange(5),i)\n",
    "    name = disc + str(i)\n",
    "\n",
    "    train_generator1 = GraphemeGenerator(fold_train, batch_size, dim , \n",
    "                                        shuffle = True,  \n",
    "                                        kfold = t_fold, \n",
    "                                        transform = train_transform)\n",
    "\n",
    "    cut_src_gen = GraphemeGenerator(fold_train, 1, dim , \n",
    "                                        shuffle = True,  \n",
    "                                        kfold = t_fold)\n",
    "\n",
    "    train_generator = CutMixGenerator(\n",
    "        generator1=train_generator1,\n",
    "        generator2=cut_src_gen,\n",
    "        mixup_p = 0.2,\n",
    "        cut_p=0.2\n",
    "    )\n",
    "    \n",
    "    val_generator = GraphemeGenerator(fold_train, 12*gpus, dim, kfold = (i,), shuffle = False)\n",
    "    callbacks = Call_Back(name,val_generator)    \n",
    "    \n",
    "    model = create_model(backbone, input_shape, slr=0.003,gpus=gpus)\n",
    "        \n",
    "    train_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        workers=32,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    historys.append(train_history)\n",
    "    model.load_weights('./'+'best_avg_recall' + name +'.h5')\n",
    "    single_model = model.layers[-4]\n",
    "    single_model.save_weights('./best_avg_recall_single'+name+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
