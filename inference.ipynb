{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/grapheme-sub/efficientnet-1.0.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (0.16.2)\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.6/site-packages (from efficientnet==1.0.0) (1.0.8)\r\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.4.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.4)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (1.1.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (3.0.3)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (2.6.1)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0) (5.4.1)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.18.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (2.10.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0) (4.4.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.4.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (2.8.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0) (1.14.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0) (45.2.0.post20200210)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.0.0\r\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Lambda, Input, GlobalAveragePooling2D\n",
    "from math import ceil\n",
    "\n",
    "# Install EfficientNet\n",
    "!pip install '../input/grapheme-sub/efficientnet-1.0.0-py3-none-any.whl'\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "FACTOR = 1.0\n",
    "HEIGHT_NEW = int(HEIGHT * FACTOR)\n",
    "WIDTH_NEW = int(WIDTH * FACTOR)\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 16\n",
    "stats = (0.0692, 0.2051)\n",
    "# Dir\n",
    "DIR = '../input/bengaliai-cv19'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img, org_width, org_height):\n",
    "    # Invert\n",
    "    img = 255 - img\n",
    "    # Normalize\n",
    "    img = (img * (255.0 / img.max())).astype(np.uint8)\n",
    "    img = img.reshape(org_height, org_width)\n",
    "    return img    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone, input_shape):\n",
    "    base_model = backbone(input_shape=input_shape, include_top=False, weights=None)\n",
    "    curr_output = GlobalAveragePooling2D()(base_model.output)\n",
    "    oputput1 = Dense(168,  activation='softmax', name='gra') (curr_output)\n",
    "    oputput2 = Dense(11,  activation='softmax', name='vow') (curr_output)\n",
    "    oputput3 = Dense(7,  activation='softmax', name='cons') (curr_output)\n",
    "    output_tensor = [oputput1, oputput2, oputput3]\n",
    "\n",
    "    model = Model(base_model.input, output_tensor)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (HEIGHT_NEW,WIDTH_NEW,CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, X, batch_size = 16, img_size = (512, 512, 3), *args, **kwargs):\n",
    "        self.X = X\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return int(ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        X = self.__data_generation(indices)\n",
    "        return X\n",
    "    \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((len(indices), *self.img_size))\n",
    "        \n",
    "        for i, index in enumerate(indices):\n",
    "            image = self.X[index]\n",
    "            image = np.stack((image,)*CHANNELS, axis=-1)\n",
    "            image = image.reshape(-1, HEIGHT_NEW, WIDTH_NEW, CHANNELS)\n",
    "            \n",
    "            image = (image.astype(np.float32)/255.0 - stats[0])/stats[1]\n",
    "            X[i,] = image        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_model(backbone, path, input_shape=input_shape):\n",
    "    model = create_model(backbone, input_shape)\n",
    "    model.load_weights(path)\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model Weights\n",
    "models = []\n",
    "models.append(load_single_model(efn.EfficientNetB4, '../input/grapheme-sub/best_avg_recall_single_mul_addaug_EF4_Fold_1.h5')) #cv9846 lb9763 2020 ef4 fold1 \n",
    "models.append(load_single_model(efn.EfficientNetB4, '../input/grapheme-sub/best_avg_recall_single_mul_addaug_EF4_Fold_2.h5')) #cv9839 lb? 2020 ef4 fold2 \n",
    "models.append(load_single_model(efn.EfficientNetB4, '../input/grapheme-sub/best_avg_recall_single_mul_addaug_EF4_Fold_4_0.9838.h5')) #lb? 2020 ef4 fold4 \n",
    "models.append(load_single_model(efn.EfficientNetB4, '../input/grapheme-sub/best_avg_recall_single_mul_addaug_EF4_Fold_0_0.9846.h5')) #lb? 2020 ef4 fold0 \n",
    "models.append(load_single_model(efn.EfficientNetB4, '../input/grapheme-sub/best_avg_recall_single_mul_addaug_EF4_Fold_3_0.9831.h5')) #lb? 2020 ef4 fold3 \n",
    "#models.append(load_single_model(efn.EfficientNetB5, '../input/grapheme-sub/best_avg_recall_single_mul_addaug_EF5_Fold_0.h5'))  #cv9816 lb? 2021 ef5 fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create Submission File\n",
    "tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "# Create Predictions\n",
    "row_ids, targets = [], []\n",
    "\n",
    "# Loop through Test Parquet files (X)\n",
    "for i in range(0, 4):\n",
    "    # Test Files Placeholder\n",
    "    test_files = []\n",
    "\n",
    "    # Read Parquet file\n",
    "    df = pd.read_parquet(os.path.join(DIR, 'test_image_data_'+str(i)+'.parquet'))\n",
    "    # Get Image Id values\n",
    "    image_ids = df['image_id'].values \n",
    "    # Drop Image_id column\n",
    "    df = df.drop(['image_id'], axis = 1)\n",
    "\n",
    "    # Loop over rows in Dataframe and generate images \n",
    "    X = []\n",
    "    for image_id, index in zip(image_ids, range(df.shape[0])):\n",
    "        test_files.append(image_id)\n",
    "        X.append(get_img(df.loc[df.index[index]].values,WIDTH,HEIGHT))\n",
    "\n",
    "    # Data_Generator\n",
    "    data_generator_test = TestDataGenerator(X, batch_size = BATCH_SIZE, img_size = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "        \n",
    "    # Predict \n",
    "    preds  =[]\n",
    "    for model in models:\n",
    "        preds.append(model.predict_generator(data_generator_test, verbose = 1))\n",
    "    \n",
    "    # Loop over Preds    \n",
    "    for i, image_id in zip(range(len(test_files)), test_files):        \n",
    "        for subi, col in zip(range(len(preds[0])), tgt_cols):\n",
    "            prob = (preds[0][subi][i]+ preds[1][subi][i] + preds[2][subi][i]+ preds[3][subi][i]+ preds[4][subi][i])/len(models)             \n",
    "            # Set Prediction with average of 5 predictions\n",
    "            row_ids.append(str(image_id)+'_'+col)\n",
    "            sub_pred_value = np.argmax(prob)\n",
    "            targets.append(sub_pred_value)\n",
    "    \n",
    "    # Cleanup\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         row_id  target\n",
      "0          Test_0_grapheme_root       3\n",
      "1        Test_0_vowel_diacritic       0\n",
      "2    Test_0_consonant_diacritic       0\n",
      "3          Test_1_grapheme_root      93\n",
      "4        Test_1_vowel_diacritic       2\n",
      "5    Test_1_consonant_diacritic       0\n",
      "6          Test_2_grapheme_root      19\n",
      "7        Test_2_vowel_diacritic       0\n",
      "8    Test_2_consonant_diacritic       0\n",
      "9          Test_3_grapheme_root     115\n",
      "10       Test_3_vowel_diacritic       0\n",
      "11   Test_3_consonant_diacritic       0\n",
      "12         Test_4_grapheme_root      55\n",
      "13       Test_4_vowel_diacritic       4\n",
      "14   Test_4_consonant_diacritic       0\n",
      "15         Test_5_grapheme_root     115\n",
      "16       Test_5_vowel_diacritic       2\n",
      "17   Test_5_consonant_diacritic       0\n",
      "18         Test_6_grapheme_root     147\n",
      "19       Test_6_vowel_diacritic       9\n",
      "20   Test_6_consonant_diacritic       5\n",
      "21         Test_7_grapheme_root     137\n",
      "22       Test_7_vowel_diacritic       7\n",
      "23   Test_7_consonant_diacritic       0\n",
      "24         Test_8_grapheme_root     119\n",
      "25       Test_8_vowel_diacritic       9\n",
      "26   Test_8_consonant_diacritic       0\n",
      "27         Test_9_grapheme_root     133\n",
      "28       Test_9_vowel_diacritic      10\n",
      "29   Test_9_consonant_diacritic       0\n",
      "30        Test_10_grapheme_root     148\n",
      "31      Test_10_vowel_diacritic       1\n",
      "32  Test_10_consonant_diacritic       4\n",
      "33        Test_11_grapheme_root      21\n",
      "34      Test_11_vowel_diacritic       2\n",
      "35  Test_11_consonant_diacritic       0\n"
     ]
    }
   ],
   "source": [
    "# Create and Save Submission File\n",
    "submit_df = pd.DataFrame({'row_id':row_ids,'target':targets}, columns = ['row_id','target'])\n",
    "submit_df.to_csv('submission.csv', index = False)\n",
    "print(submit_df.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
